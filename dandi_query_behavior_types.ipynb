{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on notebooks in  \n",
    "https://github.com/dandi/example-notebooks/tree/master/tutorials/neurodatarehack_2024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from tqdm.notebook import tqdm\n",
    "from isodate import parse_duration, Duration\n",
    "from datetime import datetime\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")  # Suppress namespace warnings from reading older NWB files\n",
    "\n",
    "from nwbinspector.tools import get_s3_urls_and_dandi_paths\n",
    "from pynwb import NWBHDF5IO\n",
    "import remfile\n",
    "import h5py\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import lindi, pynwb\n",
    "\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = DandiAPIClient()\n",
    "dandisets = list(client.get_dandisets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nwb dandisets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802fe3d2507f41248c17b3d1240d6d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 420 NWB datasets on DANDI!\n"
     ]
    }
   ],
   "source": [
    "nwb_dandisets = []\n",
    "\n",
    "for dandiset in tqdm(dandisets):\n",
    "    raw_metadata = dandiset.get_raw_metadata()\n",
    "\n",
    "    if any(\n",
    "        data_standard['identifier'] == \"RRID:SCR_015242\"  # this is the RRID for NWB\n",
    "        for data_standard in raw_metadata['assetsSummary'].get('dataStandard', [])\n",
    "    ):\n",
    "        nwb_dandisets.append(dandiset)\n",
    "print(f\"There are currently {len(nwb_dandisets)} NWB datasets on DANDI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dandiset behavior types \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metadata = dandisets[2].get_raw_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'DANDI:000005/0.220126.1853',\n",
       " 'doi': '10.48324/dandi.000005/0.220126.1853',\n",
       " 'url': 'https://dandiarchive.org/dandiset/000005/0.220126.1853',\n",
       " 'name': 'Electrophysiology data from thalamic and cortical neurons during somatosensation',\n",
       " 'about': [{'name': 'dorsal plus ventral thalamus',\n",
       "   'schemaKey': 'Anatomy',\n",
       "   'identifier': 'UBERON:0001897'}],\n",
       " 'access': [{'status': 'dandi:OpenAccess',\n",
       "   'schemaKey': 'AccessRequirements',\n",
       "   'contactPoint': {'schemaKey': 'ContactPoint'}}],\n",
       " 'license': ['spdx:CC-BY-4.0'],\n",
       " 'version': '0.220126.1853',\n",
       " '@context': 'https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.0/context.json',\n",
       " 'citation': 'Yu, Jianing; Gutnisky, Diego A; Hires, S Andrew; Svoboda, Karel (2022) Electrophysiology data from thalamic and cortical neurons during somatosensation (Version 0.220126.1853) [Data set]. DANDI archive. https://doi.org/10.48324/dandi.000005/0.220126.1853',\n",
       " 'keywords': [],\n",
       " 'protocol': [],\n",
       " 'schemaKey': 'Dandiset',\n",
       " 'identifier': 'DANDI:000005',\n",
       " 'repository': 'https://dandiarchive.org/',\n",
       " 'contributor': [{'name': 'Yu, Jianing',\n",
       "   'roleName': ['dcite:Author'],\n",
       "   'schemaKey': 'Person',\n",
       "   'affiliation': [{'name': 'Janelia Research Campus, Howard Hughes Medical Institute',\n",
       "     'schemaKey': 'Affiliation',\n",
       "     'includeInCitation': False}],\n",
       "   'includeInCitation': True},\n",
       "  {'name': 'Gutnisky, Diego A',\n",
       "   'roleName': ['dcite:Author'],\n",
       "   'schemaKey': 'Person',\n",
       "   'affiliation': [{'name': 'Janelia Research Campus, Howard Hughes Medical Institute',\n",
       "     'schemaKey': 'Affiliation',\n",
       "     'includeInCitation': False}],\n",
       "   'includeInCitation': True},\n",
       "  {'name': 'Hires, S Andrew',\n",
       "   'roleName': ['dcite:Author'],\n",
       "   'schemaKey': 'Person',\n",
       "   'affiliation': [{'name': 'Janelia Research Campus, Howard Hughes Medical Institute',\n",
       "     'schemaKey': 'Affiliation',\n",
       "     'includeInCitation': False}],\n",
       "   'includeInCitation': True},\n",
       "  {'name': 'Svoboda, Karel',\n",
       "   'roleName': ['dcite:Author', 'dcite:ContactPerson'],\n",
       "   'schemaKey': 'Person',\n",
       "   'identifier': '0000-0002-6670-7362',\n",
       "   'affiliation': [{'name': 'Janelia Research Campus, Howard Hughes Medical Institute',\n",
       "     'roleName': [],\n",
       "     'schemaKey': 'Affiliation',\n",
       "     'identifier': 'https://ror.org/013sk6x84',\n",
       "     'contactPoint': [],\n",
       "     'includeInCitation': False}],\n",
       "   'includeInCitation': True}],\n",
       " 'dateCreated': '2020-03-16T22:52:44.757000+00:00',\n",
       " 'description': 'intracellular and extracellular electrophysiology recordings performed on mouse barrel cortex and ventral posterolateral nucleus (vpm) in whisker-based object locating task.',\n",
       " 'publishedBy': {'id': 'urn:uuid:2d3f280e-e2ec-412d-a645-a6068b39edc6',\n",
       "  'name': 'DANDI publish',\n",
       "  'endDate': '2022-01-26T18:53:25.564691+00:00',\n",
       "  'schemaKey': 'PublishActivity',\n",
       "  'startDate': '2022-01-26T18:53:25.564691+00:00',\n",
       "  'wasAssociatedWith': [{'id': 'urn:uuid:d97e4246-aa84-4b17-a7ed-15ae6c6ec912',\n",
       "    'name': 'DANDI API',\n",
       "    'version': '0.1.0',\n",
       "    'schemaKey': 'Software',\n",
       "    'identifier': 'RRID:SCR_017571'}]},\n",
       " 'studyTarget': [],\n",
       " 'assetsSummary': {'species': [{'name': 'House mouse',\n",
       "    'schemaKey': 'SpeciesType',\n",
       "    'identifier': 'http://purl.obolibrary.org/obo/NCBITaxon_10090'}],\n",
       "  'approach': [{'name': 'electrophysiological approach',\n",
       "    'schemaKey': 'ApproachType'},\n",
       "   {'name': 'optogenetic approach', 'schemaKey': 'ApproachType'}],\n",
       "  'schemaKey': 'AssetsSummary',\n",
       "  'dataStandard': [{'name': 'Neurodata Without Borders (NWB)',\n",
       "    'schemaKey': 'StandardsType',\n",
       "    'identifier': 'RRID:SCR_015242'}],\n",
       "  'numberOfBytes': 46436686324,\n",
       "  'numberOfFiles': 148,\n",
       "  'numberOfSubjects': 55,\n",
       "  'variableMeasured': ['CurrentClampStimulusSeries',\n",
       "   'CurrentClampSeries',\n",
       "   'OptogeneticSeries',\n",
       "   'ElectrodeGroup',\n",
       "   'Units'],\n",
       "  'measurementTechnique': [{'name': 'current clamp technique',\n",
       "    'schemaKey': 'MeasurementTechniqueType'},\n",
       "   {'name': 'surgical technique', 'schemaKey': 'MeasurementTechniqueType'},\n",
       "   {'name': 'spike sorting technique',\n",
       "    'schemaKey': 'MeasurementTechniqueType'}]},\n",
       " 'datePublished': '2022-01-26T18:53:25.564691+00:00',\n",
       " 'schemaVersion': '0.6.0',\n",
       " 'ethicsApproval': [],\n",
       " 'wasGeneratedBy': [],\n",
       " 'relatedResource': [{'url': 'https://doi.org/10.1038/nn.4412',\n",
       "   'name': 'Layer 4 fast-spiking interneurons filter thalamocortical signals during active somatosensation',\n",
       "   'relation': 'dcite:IsDescribedBy',\n",
       "   'schemaKey': 'Resource',\n",
       "   'identifier': 'doi:10.1038/nn.4412'}],\n",
       " 'manifestLocation': ['https://dandiarchive.s3.amazonaws.com/dandisets/000005/0.220126.1853/assets.yaml']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contains_behavior(data):\n",
    "    if isinstance(data, dict):\n",
    "        return any(contains_behavior(v) for v in data.values())\n",
    "    elif isinstance(data, list):\n",
    "        return any(contains_behavior(v) for v in data)\n",
    "    elif isinstance(data, str):\n",
    "        return 'behavior' in data.lower()\n",
    "    return False\n",
    "\n",
    "def find_behavior_keys(data, parent_key=\"\"):\n",
    "    keys_with_behavior = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "            keys_with_behavior.extend(find_behavior_keys(value, full_key))\n",
    "    elif isinstance(data, list):\n",
    "        for index, item in enumerate(data):\n",
    "            full_key = f\"{parent_key}[{index}]\"\n",
    "            # keys_with_behavior.extend(find_behavior_keys(item, full_key))\n",
    "            keys_with_behavior.extend(find_behavior_keys(item, parent_key))\n",
    "    elif isinstance(data, str):\n",
    "        if 'behavior' in data.lower():\n",
    "            keys_with_behavior.append(parent_key)\n",
    "\n",
    "    return keys_with_behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'citation', 'description', 'assetsSummary.approach.name', 'assetsSummary.measurementTechnique.name', 'relatedResource.name']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:15<00:00, 26.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(find_behavior_keys(raw_metadata))\n",
    "\n",
    "# query\n",
    "brbe_nwb_dandisets = []\n",
    "\n",
    "# contains 'behavior'\n",
    "for dset in tqdm(nwb_dandisets):\n",
    "    raw_metadata = dset.get_raw_metadata()\n",
    "\n",
    "    if contains_behavior(raw_metadata):\n",
    "        behavior_keys = find_behavior_keys(raw_metadata)\n",
    "        brbe_nwb_dandisets.append(dset)\n",
    "\n",
    "print(len(brbe_nwb_dandisets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04070c804c44eb5821bca85117e05fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'assetsSummary.approach.name': 122,\n",
       "         'assetsSummary.measurementTechnique.name': 122,\n",
       "         'description': 96,\n",
       "         'assetsSummary.variableMeasured': 91,\n",
       "         'name': 29,\n",
       "         'citation': 29,\n",
       "         'relatedResource.name': 19,\n",
       "         'keywords': 15,\n",
       "         'relatedResource.url': 11,\n",
       "         'studyTarget': 8,\n",
       "         'contributor.name': 4,\n",
       "         'about.name': 4,\n",
       "         'relatedResource.repository': 3,\n",
       "         'contributor.affiliation.name': 2,\n",
       "         'acknowledgement': 2,\n",
       "         'relatedResource.identifier': 1,\n",
       "         'wasGeneratedBy.description': 1})"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contains a behavior key\n",
    "\n",
    "behavior_keys_list = []\n",
    "behavior_keys_dandisets = []\n",
    "for dset in tqdm(nwb_dandisets):\n",
    "    raw_metadata = dset.get_raw_metadata()\n",
    "\n",
    "    behavior_keys = find_behavior_keys(raw_metadata)\n",
    "    behavior_keys_list.extend(behavior_keys)\n",
    "    \n",
    "    if behavior_keys: \n",
    "        approaches = raw_metadata['assetsSummary'].get('approach', [])\n",
    "        if (\n",
    "            any('electrophysiological' in a.get('name', '') for a in approaches)\n",
    "        ):\n",
    "            exist_ephys = True\n",
    "        else: \n",
    "            exist_ephys = False\n",
    "        if any('assetssummary' in x.lower() for x in behavior_keys):\n",
    "            exist_asset = True \n",
    "        else:\n",
    "            exist_asset = False  \n",
    "        behavior_keys_dandisets.append({\n",
    "            \"dandiset_id\": dset.identifier,\n",
    "            \"dandiset\": dset,\n",
    "            \"behavior_keys\": behavior_keys,\n",
    "            \"asset\": exist_asset,\n",
    "            \"ephys\": exist_ephys\n",
    "        })\n",
    "\n",
    "behavior_keys_dandisets = pd.DataFrame(behavior_keys_dandisets)\n",
    "# count occurrences of each key\n",
    "behavior_keys_counter = Counter(behavior_keys_list)\n",
    "behavior_keys_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dandiset_id</th>\n",
       "      <th>dandiset</th>\n",
       "      <th>behavior_keys</th>\n",
       "      <th>asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000003</td>\n",
       "      <td>DANDI:000003/0.250624.0409</td>\n",
       "      <td>[name, citation, description, assetsSummary.ap...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000004</td>\n",
       "      <td>DANDI:000004/0.220126.1852</td>\n",
       "      <td>[contributor.affiliation.name, contributor.aff...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000006</td>\n",
       "      <td>DANDI:000006/0.220126.1855</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000009</td>\n",
       "      <td>DANDI:000009/0.220126.1903</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000010</td>\n",
       "      <td>DANDI:000010/0.220126.1905</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>001515</td>\n",
       "      <td>DANDI:001515/draft</td>\n",
       "      <td>[description]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>001530</td>\n",
       "      <td>DANDI:001530/draft</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>001533</td>\n",
       "      <td>DANDI:001533/draft</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.me...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>001539</td>\n",
       "      <td>DANDI:001539/0.250804.1538</td>\n",
       "      <td>[description, assetsSummary.approach.name, ass...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>001543</td>\n",
       "      <td>DANDI:001543/draft</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dandiset_id                    dandiset  \\\n",
       "0        000003  DANDI:000003/0.250624.0409   \n",
       "1        000004  DANDI:000004/0.220126.1852   \n",
       "2        000006  DANDI:000006/0.220126.1855   \n",
       "3        000009  DANDI:000009/0.220126.1903   \n",
       "4        000010  DANDI:000010/0.220126.1905   \n",
       "..          ...                         ...   \n",
       "173      001515          DANDI:001515/draft   \n",
       "174      001530          DANDI:001530/draft   \n",
       "175      001533          DANDI:001533/draft   \n",
       "176      001539  DANDI:001539/0.250804.1538   \n",
       "177      001543          DANDI:001543/draft   \n",
       "\n",
       "                                         behavior_keys  asset  \n",
       "0    [name, citation, description, assetsSummary.ap...   True  \n",
       "1    [contributor.affiliation.name, contributor.aff...  False  \n",
       "2    [assetsSummary.approach.name, assetsSummary.va...   True  \n",
       "3    [assetsSummary.approach.name, assetsSummary.va...   True  \n",
       "4    [assetsSummary.approach.name, assetsSummary.va...   True  \n",
       "..                                                 ...    ...  \n",
       "173                                      [description]  False  \n",
       "174  [assetsSummary.approach.name, assetsSummary.va...   True  \n",
       "175  [assetsSummary.approach.name, assetsSummary.me...   True  \n",
       "176  [description, assetsSummary.approach.name, ass...   True  \n",
       "177  [assetsSummary.approach.name, assetsSummary.va...   True  \n",
       "\n",
       "[178 rows x 4 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_keys_dandisets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dandiset_id</th>\n",
       "      <th>dandiset</th>\n",
       "      <th>behavior_keys</th>\n",
       "      <th>asset</th>\n",
       "      <th>ephys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000003</td>\n",
       "      <td>DANDI:000003/0.250624.0409</td>\n",
       "      <td>[name, citation, description, assetsSummary.ap...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000006</td>\n",
       "      <td>DANDI:000006/0.220126.1855</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000009</td>\n",
       "      <td>DANDI:000009/0.220126.1903</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000010</td>\n",
       "      <td>DANDI:000010/0.220126.1905</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000011</td>\n",
       "      <td>DANDI:000011/0.220126.1907</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>001347</td>\n",
       "      <td>DANDI:001347/0.250528.0702</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>001371</td>\n",
       "      <td>DANDI:001371/draft</td>\n",
       "      <td>[description, assetsSummary.approach.name, ass...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>001530</td>\n",
       "      <td>DANDI:001530/draft</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>001533</td>\n",
       "      <td>DANDI:001533/draft</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.me...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>001539</td>\n",
       "      <td>DANDI:001539/0.250804.1538</td>\n",
       "      <td>[description, assetsSummary.approach.name, ass...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dandiset_id                    dandiset  \\\n",
       "0        000003  DANDI:000003/0.250624.0409   \n",
       "2        000006  DANDI:000006/0.220126.1855   \n",
       "3        000009  DANDI:000009/0.220126.1903   \n",
       "4        000010  DANDI:000010/0.220126.1905   \n",
       "5        000011  DANDI:000011/0.220126.1907   \n",
       "..          ...                         ...   \n",
       "164      001347  DANDI:001347/0.250528.0702   \n",
       "167      001371          DANDI:001371/draft   \n",
       "174      001530          DANDI:001530/draft   \n",
       "175      001533          DANDI:001533/draft   \n",
       "176      001539  DANDI:001539/0.250804.1538   \n",
       "\n",
       "                                         behavior_keys  asset  ephys  \n",
       "0    [name, citation, description, assetsSummary.ap...   True   True  \n",
       "2    [assetsSummary.approach.name, assetsSummary.va...   True   True  \n",
       "3    [assetsSummary.approach.name, assetsSummary.va...   True   True  \n",
       "4    [assetsSummary.approach.name, assetsSummary.va...   True   True  \n",
       "5    [assetsSummary.approach.name, assetsSummary.va...   True   True  \n",
       "..                                                 ...    ...    ...  \n",
       "164  [assetsSummary.approach.name, assetsSummary.va...   True   True  \n",
       "167  [description, assetsSummary.approach.name, ass...   True   True  \n",
       "174  [assetsSummary.approach.name, assetsSummary.va...   True   True  \n",
       "175  [assetsSummary.approach.name, assetsSummary.me...   True   True  \n",
       "176  [description, assetsSummary.approach.name, ass...   True   True  \n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_assets_dandisets = behavior_keys_dandisets[(behavior_keys_dandisets['asset']==True) & \n",
    "                                                    (behavior_keys_dandisets['ephys']==True)\n",
    "                                                    ]\n",
    "behavior_assets_dandisets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2016a3864576488d8e6f0014c5ad2859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "beh_asset_nwb_dandisets = []\n",
    "\n",
    "for dset in tqdm(nwb_dandisets):\n",
    "    raw_metadata = dset.get_raw_metadata()\n",
    "\n",
    "    approaches = raw_metadata['assetsSummary'].get('approach', [])\n",
    "    measurement_techniques = raw_metadata['assetsSummary'].get('measurementTechnique', [])\n",
    "    variables_measured = raw_metadata['assetsSummary'].get('variableMeasured', [])\n",
    "\n",
    "    if (\n",
    "        any('behavior' in a.get('name', '').lower() for a in approaches) or\n",
    "        any('behavior' in m.get('name', '').lower() for m in measurement_techniques) or\n",
    "        any('behavior' in str(v).lower() for v in variables_measured)\n",
    "    ):\n",
    "        beh_asset_nwb_dandisets.append(dset)\n",
    "\n",
    "print(len(beh_asset_nwb_dandisets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read nwb via lindi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = behavior_assets_dandisets.iloc[1]['dandiset'].get_raw_metadata()['id'].split('/')[0].split(':')[-1]\n",
    "s3_urls = get_s3_urls_and_dandi_paths(dandiset_id=dandiset_id)\n",
    "# print(s3_urls)\n",
    "# print(list(s3_urls.values()))\n",
    "\n",
    "filepath = list(s3_urls.values())[0]\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    asset = client.get_dandiset(dandiset_id).get_asset_by_path(filepath)\n",
    "    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "f = lindi.LindiH5pyFile.from_hdf5_file(asset.download_url)\n",
    "nwb = pynwb.NWBHDF5IO(file=f, mode='r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([root pynwb.file.NWBFile at 0x6288612832\n",
       "Fields:\n",
       "  acquisition: {\n",
       "    lick_times <class 'pynwb.behavior.BehavioralEvents'>\n",
       "  }\n",
       "  devices: {\n",
       "    H-129 <class 'pynwb.device.Device'>\n",
       "  }\n",
       "  electrode_groups: {\n",
       "    H-129: 64 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
       "  }\n",
       "  electrodes: electrodes <class 'pynwb.ecephys.ElectrodesTable'>\n",
       "  experiment_description: Extracellular electrophysiology recordings performed on mouse anterior lateral motor cortex (ALM) in delay response task. Neural activity from two neuron populations, pyramidal track upper and lower, were characterized, in relation to movement execution.\n",
       "  experimenter: ['Mike Economo']\n",
       "  file_create_date: [datetime.datetime(2019, 10, 7, 17, 40, 36, 567483, tzinfo=tzoffset(None, -18000))]\n",
       "  identifier: anm369962_2017-03-09_0\n",
       "  institution: Janelia Research Campus\n",
       "  intervals: {\n",
       "    trials <class 'pynwb.epoch.TimeIntervals'>\n",
       "  }\n",
       "  keywords: <LindiH5pyDataset: /general/keywords>\n",
       "  related_publications: ['doi:10.1038/s41586-018-0642-9']\n",
       "  session_start_time: 2017-03-09 00:00:00-06:00\n",
       "  subject: subject pynwb.file.Subject at 0x13824910480\n",
       "Fields:\n",
       "  sex: U\n",
       "  species: Mus musculus\n",
       "  subject_id: anm369962\n",
       "\n",
       "  timestamps_reference_time: 2017-03-09 00:00:00-06:00\n",
       "  trials: trials <class 'pynwb.epoch.TimeIntervals'>\n",
       "  units: units <class 'pynwb.misc.Units'>\n",
       ", units pynwb.misc.Units at 0x6068938512\n",
       "Fields:\n",
       "  colnames: ['depth' 'quality' 'cell_type' 'spike_times' 'electrodes']\n",
       "  columns: (\n",
       "    depth <class 'hdmf.common.table.VectorData'>,\n",
       "    quality <class 'hdmf.common.table.VectorData'>,\n",
       "    cell_type <class 'hdmf.common.table.VectorData'>,\n",
       "    spike_times_index <class 'hdmf.common.table.VectorIndex'>,\n",
       "    spike_times <class 'hdmf.common.table.VectorData'>,\n",
       "    electrodes_index <class 'hdmf.common.table.VectorIndex'>,\n",
       "    electrodes <class 'hdmf.common.table.DynamicTableRegion'>\n",
       "  )\n",
       "  description: Autogenerated by NWBFile\n",
       "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
       "  waveform_unit: volts\n",
       ", electrodes hdmf.common.table.DynamicTableRegion at 0x13824787392\n",
       "    Target table: electrodes pynwb.ecephys.ElectrodesTable at 0x5751974368\n",
       ", <hdmf.common.table.VectorIndex object at 0x155860e90>, <hdmf.common.table.VectorData object at 0x338059c80>, <hdmf.common.table.VectorIndex object at 0x155862f90>, <hdmf.common.table.VectorData object at 0x176d4a780>, <hdmf.common.table.VectorData object at 0x176d4a8e0>, <hdmf.common.table.VectorData object at 0x176d4a830>, <hdmf.common.table.ElementIdentifiers object at 0x338058470>, subject pynwb.file.Subject at 0x13824910480\n",
       "Fields:\n",
       "  sex: U\n",
       "  species: Mus musculus\n",
       "  subject_id: anm369962\n",
       ", trials pynwb.epoch.TimeIntervals at 0x6068934352\n",
       "Fields:\n",
       "  colnames: ['start_time' 'stop_time' 'type' 'response' 'stim_present' 'is_good'\n",
       " 'cue_start_time' 'pole_in_time' 'pole_out_time']\n",
       "  columns: (\n",
       "    start_time <class 'hdmf.common.table.VectorData'>,\n",
       "    stop_time <class 'hdmf.common.table.VectorData'>,\n",
       "    type <class 'hdmf.common.table.VectorData'>,\n",
       "    response <class 'hdmf.common.table.VectorData'>,\n",
       "    stim_present <class 'hdmf.common.table.VectorData'>,\n",
       "    is_good <class 'hdmf.common.table.VectorData'>,\n",
       "    cue_start_time <class 'hdmf.common.table.VectorData'>,\n",
       "    pole_in_time <class 'hdmf.common.table.VectorData'>,\n",
       "    pole_out_time <class 'hdmf.common.table.VectorData'>\n",
       "  )\n",
       "  description: experimental trials\n",
       "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
       ", <hdmf.common.table.VectorData object at 0x3380581b0>, <hdmf.common.table.VectorData object at 0x338059d30>, <hdmf.common.table.VectorData object at 0x338058050>, <hdmf.common.table.VectorData object at 0x338059bd0>, <hdmf.common.table.VectorData object at 0x338059b20>, <hdmf.common.table.VectorData object at 0x338058260>, <hdmf.common.table.VectorData object at 0x338059a70>, <hdmf.common.table.VectorData object at 0x176d4ac50>, <hdmf.common.table.VectorData object at 0x176d4b070>, <hdmf.common.table.ElementIdentifiers object at 0x176d4b120>, H-129 pynwb.device.Device at 0x13824910640, H-129: 64 pynwb.ecephys.ElectrodeGroup at 0x13824911440\n",
       "Fields:\n",
       "  description: N/A\n",
       "  device: H-129 pynwb.device.Device at 0x13824910640\n",
       "  location: brain_region: ALM; brain_subregion: N/A; cortical_layer: 5; hemisphere: left; brain_location_full_name: N/A\n",
       ", electrodes pynwb.ecephys.ElectrodesTable at 0x5751974368\n",
       "Fields:\n",
       "  colnames: ['x' 'y' 'z' 'imp' 'location' 'filtering' 'group' 'group_name']\n",
       "  columns: (\n",
       "    x <class 'hdmf.common.table.VectorData'>,\n",
       "    y <class 'hdmf.common.table.VectorData'>,\n",
       "    z <class 'hdmf.common.table.VectorData'>,\n",
       "    imp <class 'hdmf.common.table.VectorData'>,\n",
       "    location <class 'hdmf.common.table.VectorData'>,\n",
       "    filtering <class 'hdmf.common.table.VectorData'>,\n",
       "    group <class 'hdmf.common.table.VectorData'>,\n",
       "    group_name <class 'hdmf.common.table.VectorData'>\n",
       "  )\n",
       "  description: metadata about extracellular electrodes\n",
       "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
       ", <hdmf.common.table.VectorData object at 0x176d4a360>, <hdmf.common.table.VectorData object at 0x176d4a990>, <hdmf.common.table.VectorData object at 0x176d4aaf0>, <hdmf.common.table.VectorData object at 0x176d4a620>, <hdmf.common.table.VectorData object at 0x176d4ad00>, <hdmf.common.table.VectorData object at 0x176d4a2b0>, <hdmf.common.table.VectorData object at 0x176d4a570>, <hdmf.common.table.VectorData object at 0x176d4a6d0>, <hdmf.common.table.ElementIdentifiers object at 0x176d4aa40>, lick_times pynwb.behavior.BehavioralEvents at 0x13824910320\n",
       "Fields:\n",
       "  time_series: {\n",
       "    lick_left_times <class 'pynwb.base.TimeSeries'>,\n",
       "    lick_right_times <class 'pynwb.base.TimeSeries'>\n",
       "  }\n",
       ", lick_right_times pynwb.base.TimeSeries at 0x13824908720\n",
       "Fields:\n",
       "  comments: no comments\n",
       "  conversion: 1.0\n",
       "  data: <LindiH5pyDataset: /acquisition/lick_times/lick_right_times/data>\n",
       "  description: no description\n",
       "  interval: 1\n",
       "  offset: 0.0\n",
       "  resolution: 0.0\n",
       "  timestamps: <LindiH5pyDataset: /acquisition/lick_times/lick_right_times/timestamps>\n",
       "  timestamps_unit: seconds\n",
       "  unit: a.u.\n",
       ", lick_left_times pynwb.base.TimeSeries at 0x13824908080\n",
       "Fields:\n",
       "  comments: no comments\n",
       "  conversion: 1.0\n",
       "  data: <LindiH5pyDataset: /acquisition/lick_times/lick_left_times/data>\n",
       "  description: no description\n",
       "  interval: 1\n",
       "  offset: 0.0\n",
       "  resolution: 0.0\n",
       "  timestamps: <LindiH5pyDataset: /acquisition/lick_times/lick_left_times/timestamps>\n",
       "  timestamps_unit: seconds\n",
       "  unit: a.u.\n",
       "])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb.objects.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('Extracellular electrophysiology recordings performed on mouse anterior lateral motor cortex (ALM) in delay response task. Neural activity from two neuron populations, pyramidal track upper and lower, were characterized, in relation to movement execution.')"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb.experiment_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[lick_right_times pynwb.base.TimeSeries at 0x5487907440\n",
       " Fields:\n",
       "   comments: no comments\n",
       "   conversion: 1.0\n",
       "   data: <LindiH5pyDataset: /acquisition/lick_times/lick_right_times/data>\n",
       "   description: no description\n",
       "   interval: 1\n",
       "   offset: 0.0\n",
       "   resolution: 0.0\n",
       "   timestamps: <LindiH5pyDataset: /acquisition/lick_times/lick_right_times/timestamps>\n",
       "   timestamps_unit: seconds\n",
       "   unit: a.u.,\n",
       " lick_left_times pynwb.base.TimeSeries at 0x5487904720\n",
       " Fields:\n",
       "   comments: no comments\n",
       "   conversion: 1.0\n",
       "   data: <LindiH5pyDataset: /acquisition/lick_times/lick_left_times/data>\n",
       "   description: no description\n",
       "   interval: 1\n",
       "   offset: 0.0\n",
       "   resolution: 0.0\n",
       "   timestamps: <LindiH5pyDataset: /acquisition/lick_times/lick_left_times/timestamps>\n",
       "   timestamps_unit: seconds\n",
       "   unit: a.u.]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in nwb.objects.values() if isinstance(x, pynwb.behavior.TimeSeries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[x for x in nwb.objects.values() if isinstance(x, pynwb.behavior.SpatialSeries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time differences: [0.144829 0.16667  0.128495 ... 0.140833 0.127666 0.183499]\n",
      "Average time resolution: 1.1241294529801327\n"
     ]
    }
   ],
   "source": [
    "time_array = [x for x in nwb.objects.values() if isinstance(x, pynwb.behavior.TimeSeries)][0].timestamps[:]\n",
    "\n",
    "# differences between consecutive elements\n",
    "time_differences = np.diff(time_array)\n",
    "\n",
    "# Calculate the average difference\n",
    "average_time_resolution = np.mean(time_differences)\n",
    "\n",
    "# Print the result\n",
    "print(\"Time differences:\", time_differences)\n",
    "print(\"Average time resolution:\", average_time_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# behavior asset temporal resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dandiset name  \n",
    "get filepaths (for now [0])  \n",
    "get file, file.download_url (api dandi path)  \n",
    "stream nwb file  \n",
    "check if pynwb.behavior class is empty, which  \n",
    "calculate time resolution\n",
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynwb.behavior\n",
    "import inspect\n",
    "\n",
    "def get_non_empty_behavior_classes(nwb):\n",
    "    \"\"\"\n",
    "    Function to find non-empty pynwb.behavior classes in an NWB file.\n",
    "\n",
    "    Parameters:\n",
    "        nwb: The NWB file object.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are class names and values are counts of non-empty instances.\n",
    "    \"\"\"\n",
    "    # Get all classes in pynwb.behavior\n",
    "    behavior_classes = [\n",
    "        cls for name, cls in inspect.getmembers(pynwb.behavior, inspect.isclass)\n",
    "        if cls.__module__ == 'pynwb.behavior'\n",
    "    ]\n",
    "\n",
    "    # Check which classes are non-empty\n",
    "    non_empty_classes = {}\n",
    "\n",
    "    for behavior_class in behavior_classes:\n",
    "        non_empty_objects = [\n",
    "            x for x in nwb.objects.values() if isinstance(x, behavior_class)\n",
    "        ]\n",
    "        if non_empty_objects:  # If the list is not empty\n",
    "            non_empty_classes[behavior_class.__name__] = {\n",
    "                'count': len(non_empty_objects),\n",
    "                'objects': non_empty_objects,\n",
    "                }\n",
    "\n",
    "    return non_empty_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc56cb30b9f41059aacd867dab6cef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "behavior_assets_dandisets['filepaths'] = ''\n",
    "\n",
    "for i, dset in tqdm(behavior_assets_dandisets.iterrows(), total=len(behavior_assets_dandisets)):\n",
    "    # if i >2:\n",
    "    #     break\n",
    "    dandiset_id = dset['dandiset'].get_raw_metadata()['id'].split('/')[0].split(':')[-1]\n",
    "    with DandiAPIClient() as client:\n",
    "        c=client.get_dandiset(dandiset_id)\n",
    "    files = [asset for asset in c.get_assets()]\n",
    "    behavior_assets_dandisets.at[i, 'filepaths'] = files\n",
    "    # print(files[0].path)\n",
    "\n",
    "behavior_assets_dandisets = behavior_assets_dandisets.reset_index()\n",
    "behavior_assets_dandisets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dandiarchive.s3.amazonaws.com/blobs/390/a27/390a27ba-13ed-42fb-8709-8fa6bbcca456'"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0].get_content_url(follow_redirects=1, strip_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_info_from_behavior_class(behavior_class, nwb=None):\n",
    "    # ignore pupil tracking for now\n",
    "\n",
    "    time_info = {}\n",
    "    behavior_keys = behavior_class.keys()\n",
    "\n",
    "    spatial_key_list = ['SpatialSeries', 'Position', 'Eyetracking', 'CompassDirection']\n",
    "    if behavior_keys:\n",
    "        for key in behavior_keys:\n",
    "            try:\n",
    "                if key == 'BehavioralEvents':\n",
    "                    try:\n",
    "                        time_series = behavior_class[key]['objects'][0].time_series\n",
    "                        time_stamps = list(time_series.values())[0].timestamps[:100]\n",
    "                        diffs = np.diff(time_stamps)\n",
    "                        mean_diff = np.mean(diffs)\n",
    "                        std_diff = np.std(diffs)\n",
    "\n",
    "                        time_info[key] = {\n",
    "                            \"mean_event_diff\": np.round(mean_diff, 6),\n",
    "                            \"std_event_diff\": np.round(std_diff, 6)\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        time_info[key] = e\n",
    "                \n",
    "                elif key == 'BehavioralTimeSeries':\n",
    "                    obj_time_infos = {}\n",
    "                    for i in range(len(behavior_class[key]['objects'])):\n",
    "                        obj = behavior_class[key]['objects'][i]\n",
    "                        try:\n",
    "                            # all = [x for x in nwb.objects.values() if isinstance(x, pynwb.behavior.TimeSeries)]\n",
    "                            # time_stamps = all[0].timestamps[:1000]\n",
    "                            list_dicts = list(obj.time_series.values())\n",
    "                            print(len(list_dicts))\n",
    "                            for j in range(len(list_dicts)):\n",
    "                                ts = list_dicts[j]\n",
    "                                print(ts)\n",
    "                                starting_time = ts.starting_time\n",
    "                                starting_time_unit = ts.starting_time_unit\n",
    "                                rate = ts.rate\n",
    "\n",
    "                                time_stamps = ts.timestamps[:500]\n",
    "                                if time_stamps is not None:\n",
    "                                    diffs = np.diff(time_stamps)\n",
    "                                    mean_diff = np.mean(diffs)\n",
    "                                    std_diff = np.std(diffs)\n",
    "                                else:\n",
    "                                    diffs = None\n",
    "                                    mean_diff = None\n",
    "                                    std_diff = None\n",
    "\n",
    "                                obj_time_infos[obj.name] = {\n",
    "                                    'name': obj.name,\n",
    "                                    'rate': rate,\n",
    "                                    'starting_time': starting_time,\n",
    "                                    'starting_time_unit': starting_time_unit,\n",
    "                                    \"mean_diff\": np.round(mean_diff, 6),\n",
    "                                    \"std_diff\": np.round(std_diff, 6)\n",
    "                                }\n",
    "                        except Exception as e:\n",
    "                            obj_time_infos[obj.name] = e\n",
    "                    time_info[key] = obj_time_infos\n",
    "                    \n",
    "                elif key in spatial_key_list:\n",
    "                    obj_time_infos = {}\n",
    "                    for i in range(len(behavior_class[key]['objects'])):\n",
    "                        obj = behavior_class[key]['objects'][i]\n",
    "                        try:\n",
    "                            # all = [x for x in nwb.objects.values() if isinstance(x, pynwb.behavior.TimeSeries)]\n",
    "                            # return all \n",
    "                            starting_time = obj.starting_time\n",
    "                            starting_time_unit = obj.starting_time_unit\n",
    "                            rate = obj.rate\n",
    "                            \n",
    "                            time_stamps = obj.timestamps[:500]\n",
    "                            diffs = np.diff(time_stamps)\n",
    "                            mean_diff = np.mean(diffs)\n",
    "                            std_diff = np.std(diffs)\n",
    "\n",
    "                            obj_time_infos[obj.name] = {\n",
    "                                'name': obj.name,\n",
    "                                'rate': rate,\n",
    "                                'starting_time': starting_time,\n",
    "                                'starting_time_unit': starting_time_unit,\n",
    "                                \"mean_diff\": np.round(mean_diff, 6),\n",
    "                                \"std_diff\": np.round(std_diff, 6)\n",
    "                            }\n",
    "                            \n",
    "                            if rate is  None:\n",
    "                                rate = 'no rate, check timestamps'\n",
    "                              \n",
    "                            \n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            obj_time_infos[obj.name] = e\n",
    "                    time_info[key] = obj_time_infos\n",
    "            except Exception as e:\n",
    "                time_info[key] = Exception\n",
    "                    \n",
    "\n",
    "    return time_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# behavior_assets_dandisets['experiment_description'] = ''\n",
    "# behavior_assets_dandisets['behavior_class'] = ''\n",
    "# behavior_assets_dandisets['time_info'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_storage_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bootcamp/lib/python3.13/site-packages/IPython/core/formatters.py:406\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    404\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bootcamp/lib/python3.13/site-packages/hdmf/container.py:676\u001b[39m, in \u001b[36mContainer._repr_html_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    674\u001b[39m html_repr += \u001b[33m\"\u001b[39m\u001b[33m<div class=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontainer-wrap\u001b[39m\u001b[33m'\u001b[39m\u001b[33m>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    675\u001b[39m html_repr += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<div class=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontainer-header\u001b[39m\u001b[33m'\u001b[39m\u001b[33m><div class=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mxr-obj-type\u001b[39m\u001b[33m'\u001b[39m\u001b[33m><h3>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheader_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</h3></div></div>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m html_repr += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    677\u001b[39m html_repr += \u001b[33m\"\u001b[39m\u001b[33m</div>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html_repr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bootcamp/lib/python3.13/site-packages/hdmf/container.py:690\u001b[39m, in \u001b[36mContainer._generate_html_repr\u001b[39m\u001b[34m(self, fields, level, access_code, is_field)\u001b[39m\n\u001b[32m    688\u001b[39m             html_repr += value._generate_field_html(key, value, level, current_access_code)\n\u001b[32m    689\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m             html_repr += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_field_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_access_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fields, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m index, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fields):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bootcamp/lib/python3.13/site-packages/hdmf/container.py:717\u001b[39m, in \u001b[36mContainer._generate_field_html\u001b[39m\u001b[34m(self, key, value, level, access_code)\u001b[39m\n\u001b[32m    714\u001b[39m is_array_data = \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_array_data:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     html_content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_array_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mgenerate_html_repr\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    719\u001b[39m     html_content = value.generate_html_repr(level + \u001b[32m1\u001b[39m, access_code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bootcamp/lib/python3.13/site-packages/hdmf/container.py:759\u001b[39m, in \u001b[36mContainer._generate_array_html\u001b[39m\u001b[34m(self, array, level)\u001b[39m\n\u001b[32m    753\u001b[39m     repr_html = generate_array_html_repr(array_info_dict, array.data, \u001b[33m\"\u001b[39m\u001b[33mDataIO\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m it_was_read_with_io:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# The backend handles the representation here. Two special cases worth noting:\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# 1. Array-type attributes (e.g., start_frame in ImageSeries) remain NumPy arrays\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m#    even when their parent container has an IO\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;66;03m# 2. Data may have been modified after being read from storage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     repr_html = \u001b[43mread_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_dataset_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Not sure which object could get here\u001b[39;00m\n\u001b[32m    761\u001b[39m     object_class = array.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bootcamp/lib/python3.13/site-packages/hdmf/backends/hdf5/h5tools.py:1502\u001b[39m, in \u001b[36mHDF5IO.generate_dataset_html\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m   1500\u001b[39m dataset_type = \u001b[33m\"\u001b[39m\u001b[33mHDF5 dataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# get info from hdf5 dataset\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m compressed_size = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_storage_size\u001b[49m()\n\u001b[32m   1503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[33m\"\u001b[39m\u001b[33mnbytes\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# TODO: Remove this after h5py minimal version is larger than 3.0\u001b[39;00m\n\u001b[32m   1504\u001b[39m     uncompressed_size = dataset.nbytes\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'get_storage_size'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x14377444368\n",
       "Fields:\n",
       "  experiment_description: regional and Yeo-network ketamine change in response to eyepuff, with key clusters\n",
       "  experimenter: ['Kauvar, Isaac' 'Richman, Ethan' 'Liu, Tony']\n",
       "  file_create_date: [datetime.datetime(2025, 2, 23, 19, 13, 27, 945390, tzinfo=tzoffset(None, -18000))]\n",
       "  identifier: kauvar-richman-liu-fig3\n",
       "  institution: Stanford University\n",
       "  keywords: <LindiH5pyDataset: /general/keywords>\n",
       "  lab: Karl Deisseroth Lab\n",
       "  scratch: {\n",
       "    ACC_change <class 'pynwb.core.ScratchData'>,\n",
       "    ACC_contour <class 'pynwb.core.ScratchData'>,\n",
       "    AG_change <class 'pynwb.core.ScratchData'>,\n",
       "    AG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    AMY_change <class 'pynwb.core.ScratchData'>,\n",
       "    AMY_contour <class 'pynwb.core.ScratchData'>,\n",
       "    BG_change <class 'pynwb.core.ScratchData'>,\n",
       "    BG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    CS_change <class 'pynwb.core.ScratchData'>,\n",
       "    CS_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Default_change <class 'pynwb.core.ScratchData'>,\n",
       "    Default_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Dorsal Attention_change <class 'pynwb.core.ScratchData'>,\n",
       "    Dorsal Attention_contour <class 'pynwb.core.ScratchData'>,\n",
       "    FG_change <class 'pynwb.core.ScratchData'>,\n",
       "    FG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    FO_change <class 'pynwb.core.ScratchData'>,\n",
       "    FO_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Frontoparietal_change <class 'pynwb.core.ScratchData'>,\n",
       "    Frontoparietal_contour <class 'pynwb.core.ScratchData'>,\n",
       "    HIPP_change <class 'pynwb.core.ScratchData'>,\n",
       "    HIPP_contour <class 'pynwb.core.ScratchData'>,\n",
       "    IFG_change <class 'pynwb.core.ScratchData'>,\n",
       "    IFG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    INS_change <class 'pynwb.core.ScratchData'>,\n",
       "    INS_contour <class 'pynwb.core.ScratchData'>,\n",
       "    ITG_change <class 'pynwb.core.ScratchData'>,\n",
       "    ITG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Limbic_change <class 'pynwb.core.ScratchData'>,\n",
       "    Limbic_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MCC_change <class 'pynwb.core.ScratchData'>,\n",
       "    MCC_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MFC_change <class 'pynwb.core.ScratchData'>,\n",
       "    MFC_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MFG_change <class 'pynwb.core.ScratchData'>,\n",
       "    MFG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MOG_change <class 'pynwb.core.ScratchData'>,\n",
       "    MOG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MOT_change <class 'pynwb.core.ScratchData'>,\n",
       "    MOT_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MSFG_change <class 'pynwb.core.ScratchData'>,\n",
       "    MSFG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    MTG_change <class 'pynwb.core.ScratchData'>,\n",
       "    MTG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    OP_change <class 'pynwb.core.ScratchData'>,\n",
       "    OP_contour <class 'pynwb.core.ScratchData'>,\n",
       "    ORB_change <class 'pynwb.core.ScratchData'>,\n",
       "    ORB_contour <class 'pynwb.core.ScratchData'>,\n",
       "    PHG_change <class 'pynwb.core.ScratchData'>,\n",
       "    PHG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    PMC_change <class 'pynwb.core.ScratchData'>,\n",
       "    PMC_contour <class 'pynwb.core.ScratchData'>,\n",
       "    PRECG_change <class 'pynwb.core.ScratchData'>,\n",
       "    PRECG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    SMG_change <class 'pynwb.core.ScratchData'>,\n",
       "    SMG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    SPL_change <class 'pynwb.core.ScratchData'>,\n",
       "    SPL_contour <class 'pynwb.core.ScratchData'>,\n",
       "    SS_change <class 'pynwb.core.ScratchData'>,\n",
       "    SS_contour <class 'pynwb.core.ScratchData'>,\n",
       "    STG_change <class 'pynwb.core.ScratchData'>,\n",
       "    STG_contour <class 'pynwb.core.ScratchData'>,\n",
       "    STS_change <class 'pynwb.core.ScratchData'>,\n",
       "    STS_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Somatomotor_change <class 'pynwb.core.ScratchData'>,\n",
       "    Somatomotor_contour <class 'pynwb.core.ScratchData'>,\n",
       "    THAL ANT_change <class 'pynwb.core.ScratchData'>,\n",
       "    THAL ANT_contour <class 'pynwb.core.ScratchData'>,\n",
       "    THAL MID_change <class 'pynwb.core.ScratchData'>,\n",
       "    THAL MID_contour <class 'pynwb.core.ScratchData'>,\n",
       "    THAL POS_change <class 'pynwb.core.ScratchData'>,\n",
       "    THAL POS_contour <class 'pynwb.core.ScratchData'>,\n",
       "    TP_change <class 'pynwb.core.ScratchData'>,\n",
       "    TP_contour <class 'pynwb.core.ScratchData'>,\n",
       "    VMPFC_change <class 'pynwb.core.ScratchData'>,\n",
       "    VMPFC_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Ventral Attention_change <class 'pynwb.core.ScratchData'>,\n",
       "    Ventral Attention_contour <class 'pynwb.core.ScratchData'>,\n",
       "    Visual_change <class 'pynwb.core.ScratchData'>,\n",
       "    Visual_contour <class 'pynwb.core.ScratchData'>,\n",
       "    freq_hz <class 'hdmf.common.table.DynamicTable'>,\n",
       "    time_sec <class 'hdmf.common.table.DynamicTable'>\n",
       "  }\n",
       "  session_description: Permutation-clustered ketamine change in regional SEEG spectral response to eyepuff. See `data` and `description` attributes of ScratchData objects for change spectrograms and contours.\n",
       "  session_start_time: 2000-01-01 12:00:00-08:00\n",
       "  subject: subject pynwb.file.Subject at 0x14189182352\n",
       "Fields:\n",
       "  age: P18Y/\n",
       "  age__reference: birth\n",
       "  description: all_human_subjects\n",
       "  sex: O\n",
       "  species: Homo sapiens\n",
       "  subject_id: 000\n",
       "\n",
       "  timestamps_reference_time: 2000-01-01 12:00:00-08:00"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc0e7d181c543378187fff635b87011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position_sensor1\n",
      "position_sensor0\n",
      "Position\n",
      "position\n",
      "eye_position\n",
      "Position\n",
      "R_Wrist\n",
      "R_Shoulder\n",
      "R_Elbow\n",
      "R_Ear\n",
      "Nose\n",
      "L_Wrist\n",
      "L_Shoulder\n",
      "L_Elbow\n",
      "L_Ear\n",
      "SubjectPosition\n",
      "RedLED\n",
      "BlueLED\n",
      "RedLED\n",
      "BlueLED\n",
      "SubjectPosition\n",
      "SpatialSeries\n",
      "Position\n",
      "Hand\n",
      "Eye\n",
      "Cursor\n",
      "position\n",
      "series_4\n",
      "series_3\n",
      "series_2\n",
      "series_1\n",
      "series_0\n",
      "Position\n",
      "Hand\n",
      "Eye\n",
      "DecodePos\n",
      "Cursor\n",
      "Position\n",
      "tube_top_rightCamera\n",
      "tube_top_leftCamera\n",
      "tube_bottom_rightCamera\n",
      "tube_bottom_leftCamera\n",
      "tongue_end_r_rightCamera\n",
      "tongue_end_r_leftCamera\n",
      "tongue_end_l_rightCamera\n",
      "tongue_end_l_leftCamera\n",
      "tail_start_bodyCamera\n",
      "pupil_top_r_rightCamera\n",
      "pupil_top_r_leftCamera\n",
      "pupil_right_r_rightCamera\n",
      "pupil_right_r_leftCamera\n",
      "pupil_left_r_rightCamera\n",
      "pupil_left_r_leftCamera\n",
      "pupil_bottom_r_rightCamera\n",
      "pupil_bottom_r_leftCamera\n",
      "paw_r_rightCamera\n",
      "paw_r_leftCamera\n",
      "paw_l_rightCamera\n",
      "paw_l_leftCamera\n",
      "nose_tip_rightCamera\n",
      "nose_tip_leftCamera\n",
      "Position\n",
      "SpatialSeries\n",
      "allocentric_frame_tracking\n",
      "linear_task\n",
      "position\n",
      "error_per_marker\n",
      "orientation\n",
      "direction\n",
      "position\n",
      "animal_position\n",
      "head_direction\n",
      "marker_7\n",
      "marker_6\n",
      "marker_5\n",
      "marker_4\n",
      "marker_3\n",
      "marker_2\n",
      "marker_1\n",
      "marker_0\n",
      "marker_7\n",
      "marker_6\n",
      "marker_5\n",
      "marker_4\n",
      "marker_3\n",
      "marker_2\n",
      "marker_1\n",
      "marker_0\n",
      "marker_7\n",
      "marker_6\n",
      "marker_5\n",
      "marker_4\n",
      "marker_3\n",
      "marker_2\n",
      "marker_1\n",
      "marker_0\n",
      "marker_7\n",
      "marker_6\n",
      "marker_5\n",
      "marker_4\n",
      "marker_3\n",
      "marker_2\n",
      "marker_1\n",
      "marker_0\n",
      "TrackPosition\n",
      "Whisker_label 9\n",
      "Whisker_label 8\n",
      "Whisker_label 7\n",
      "Whisker_label 6\n",
      "Whisker_label 5\n",
      "Whisker_label 4\n",
      "Whisker_label 3\n",
      "Whisker_label 2\n",
      "Whisker_label 16\n",
      "Whisker_label 15\n",
      "Whisker_label 14\n",
      "Whisker_label 13\n",
      "Whisker_label 12\n",
      "Whisker_label 11\n",
      "Whisker_label 10\n",
      "Whisker_label 1\n",
      "Whisker_angle L9\n",
      "Whisker_angle L8\n",
      "Whisker_angle L7\n",
      "Whisker_angle L6\n",
      "Whisker_angle L5\n",
      "Whisker_angle L4\n",
      "Whisker_angle L3\n",
      "Whisker_angle L2\n",
      "Whisker_angle L16\n",
      "Whisker_angle L15\n",
      "Whisker_angle L14\n",
      "Whisker_angle L13\n",
      "Whisker_angle L12\n",
      "Whisker_angle L11\n",
      "Whisker_angle L10\n",
      "Whisker_angle L1\n",
      "Phase_angle L9\n",
      "Phase_angle L8\n",
      "Phase_angle L7\n",
      "Phase_angle L6\n",
      "Phase_angle L5\n",
      "Phase_angle L4\n",
      "Phase_angle L3\n",
      "Phase_angle L2\n",
      "Phase_angle L16\n",
      "Phase_angle L15\n",
      "Phase_angle L14\n",
      "Phase_angle L13\n",
      "Phase_angle L12\n",
      "Phase_angle L11\n",
      "Phase_angle L10\n",
      "Phase_angle L1\n",
      "Curvature W4\n",
      "Curvature W3\n",
      "Curvature W2\n",
      "Curvature W1\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "SpatialSeries\n",
      "position\n",
      "series_6\n",
      "series_5\n",
      "series_4\n",
      "series_3\n",
      "series_2\n",
      "series_1\n",
      "series_0\n",
      "Position\n",
      "SpatialSeries\n",
      "Position\n",
      "SpatialSeriesLED1\n",
      "SpatialSeries\n",
      "position\n",
      "series_4\n",
      "series_3\n",
      "series_2\n",
      "series_1\n",
      "series_0\n",
      "position\n",
      "position\n",
      "Position\n",
      "cursor_pos\n",
      "hand_position\n",
      "eye_position\n",
      "CompassDirection\n",
      "Position\n",
      "position\n",
      "head-direction\n",
      "Position\n",
      "SpatialSeries\n",
      "CompassDirection\n",
      "Position\n",
      "z\n",
      "y\n",
      "x\n",
      "rz\n",
      "ry\n",
      "rx\n",
      "hand_position\n",
      "eye_position\n",
      "position\n",
      "led_1_series_6\n",
      "led_1_series_5\n",
      "led_1_series_4\n",
      "led_1_series_3\n",
      "led_1_series_2\n",
      "led_1_series_1\n",
      "led_1_series_0\n",
      "led_0_series_6\n",
      "led_0_series_5\n",
      "led_0_series_4\n",
      "led_0_series_3\n",
      "led_0_series_2\n",
      "led_0_series_1\n",
      "led_0_series_0\n",
      "view_angle\n",
      "position\n",
      "view_angle\n",
      "position\n",
      "CompassDirection\n",
      "WheelPositionSeries\n",
      "Position\n",
      "SpatialSeries\n"
     ]
    }
   ],
   "source": [
    "problems = []\n",
    "\n",
    "for i, dset in tqdm(behavior_assets_dandisets.iterrows(), total=len(behavior_assets_dandisets)):\n",
    "    try:\n",
    "\n",
    "        dandiset_id = dset['dandiset_id']\n",
    "        first_filepath = dset['filepaths'][0].path\n",
    "\n",
    "        with DandiAPIClient() as client:\n",
    "            file=client.get_dandiset(dandiset_id).get_asset_by_path(first_filepath)\n",
    "            lindi_url = file.download_url\n",
    "        f = lindi.LindiH5pyFile.from_hdf5_file(lindi_url)\n",
    "        nwb = pynwb.NWBHDF5IO(file=f, mode='r').read()\n",
    "\n",
    "        behavior_classes = get_non_empty_behavior_classes(nwb)\n",
    "        behavior_assets_dandisets.at[i, 'experiment_description'] = nwb.experiment_description\n",
    "        behavior_assets_dandisets.at[i, 'behavior_class'] = behavior_classes\n",
    "        \n",
    "        time_info = get_time_info_from_behavior_class(behavior_classes)\n",
    "        behavior_assets_dandisets.at[i, 'time_info'] = time_info\n",
    "    except Exception as e:\n",
    "        problems.append((i, dandiset_id, dset['dandiset'], e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_assets_dandisets.to_csv('./behavior_assets_dandisets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_assets_dandisets_time_info = behavior_assets_dandisets[['dandiset_id', 'dandiset', 'behavior_class', 'time_info']]\n",
    "behavior_assets_dandisets_time_info.to_csv('./behavior_assets_dandisets_time_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dandiarchive.s3.amazonaws.com/blobs/390/a27/390a27ba-13ed-42fb-8709-8fa6bbcca456\n"
     ]
    }
   ],
   "source": [
    "# remfile\n",
    "s3link = files[0].get_content_url(follow_redirects=1, strip_query=True)\n",
    "print(s3link)\n",
    "cache_dirname = './tmp/remfile_cache'\n",
    "# disk_cache = remfile.DiskCache(cache_dirname)\n",
    "rem_file = remfile.File(s3link, )\n",
    "h5py_file = h5py.File(rem_file, 'r')\n",
    "io = NWBHDF5IO(file=h5py_file)\n",
    "nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spatial series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                    17\n",
       "dandiset_id                                                          000050\n",
       "dandiset                                                 DANDI:000050/draft\n",
       "behavior_keys             [assetsSummary.approach.name, assetsSummary.va...\n",
       "asset                                                                  True\n",
       "ephys                                                                  True\n",
       "experiment_description                                                 None\n",
       "behavior_class            {'BehavioralTimeSeries': {'count': 2, 'objects...\n",
       "time_info                 {'BehavioralTimeSeries': {'mean_diff': 0.03316...\n",
       "filepaths                 [DANDI:assets/f3de94e9-6af4-4169-b911-1e7028ca...\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = behavior_assets_dandisets.iloc[11]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BehavioralTimeSeries': {'count': 2,\n",
       "  'objects': [RunningBehavior pynwb.behavior.BehavioralTimeSeries at 0x13850469520\n",
       "   Fields:\n",
       "     time_series: {\n",
       "       running_speed <class 'pynwb.base.TimeSeries'>\n",
       "     },\n",
       "   EyeBehavior pynwb.behavior.BehavioralTimeSeries at 0x13850469200\n",
       "   Fields:\n",
       "     time_series: {\n",
       "       eye_area <class 'pynwb.base.TimeSeries'>,\n",
       "       pupil_area <class 'pynwb.base.TimeSeries'>,\n",
       "       screen_coordinates_spherical <class 'pynwb.base.TimeSeries'>\n",
       "     }]}}"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['behavior_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BehavioralTimeSeries': {'mean_diff': np.float64(0.033168),\n",
       "  'std_diff': np.float64(4e-06)}}"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BehavioralTimeSeries': {'RunningBehavior': {'name': 'RunningBehavior',\n",
       "   'mean_diff': np.float64(0.033168),\n",
       "   'std_diff': np.float64(4e-06)},\n",
       "  'EyeBehavior': {'name': 'EyeBehavior',\n",
       "   'mean_diff': np.float64(0.033168),\n",
       "   'std_diff': np.float64(4e-06)}}}"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_info_from_behavior_class(data['behavior_class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'dandiset_id', 'dandiset', 'behavior_keys', 'asset', 'ephys',\n",
       "       'experiment_description', 'behavior_class', 'time_info', 'filepaths'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_assets_dandisets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dandiset_id</th>\n",
       "      <th>dandiset</th>\n",
       "      <th>behavior_keys</th>\n",
       "      <th>asset</th>\n",
       "      <th>ephys</th>\n",
       "      <th>experiment_description</th>\n",
       "      <th>behavior_class</th>\n",
       "      <th>time_info</th>\n",
       "      <th>filepaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000003</td>\n",
       "      <td>DANDI:000003/0.250624.0409</td>\n",
       "      <td>[name, citation, description, assetsSummary.ap...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'SpatialSeries': {'count': 2, 'objects': [pos...</td>\n",
       "      <td>{'SpatialSeries': {'position_sensor1': 'NoneTy...</td>\n",
       "      <td>[DANDI:assets/5e9e92e1-f044-4aa0-ab47-1cfcb889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>000006</td>\n",
       "      <td>DANDI:000006/0.220126.1855</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Extracellular electrophysiology recordings per...</td>\n",
       "      <td>{'BehavioralEvents': {'count': 1, 'objects': [...</td>\n",
       "      <td>{'BehavioralEvents': {'mean_event_diff': 0.981...</td>\n",
       "      <td>[DANDI:assets/a5ad932b-b893-4522-b989-8f406d78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>000009</td>\n",
       "      <td>DANDI:000009/0.220126.1903</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[DANDI:assets/250ea757-e6a9-4520-99b5-f2efd5e3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>000010</td>\n",
       "      <td>DANDI:000010/0.220126.1905</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Extracellular electrophysiology recordings wit...</td>\n",
       "      <td>{'BehavioralEvents': {'count': 1, 'objects': [...</td>\n",
       "      <td>{'BehavioralEvents': {'mean_event_diff': 12.00...</td>\n",
       "      <td>[DANDI:assets/6b3b38b9-0736-46a4-a348-b00af509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>000011</td>\n",
       "      <td>DANDI:000011/0.220126.1907</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Extracellular electrophysiology recordings wit...</td>\n",
       "      <td>{'BehavioralEvents': {'count': 1, 'objects': [...</td>\n",
       "      <td>{'BehavioralEvents': list index out of range}</td>\n",
       "      <td>[DANDI:assets/88dd3ee7-a37a-44b1-bb64-89855040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>000013</td>\n",
       "      <td>DANDI:000013/0.220126.2143</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Intracellular and extracellular electrophysiol...</td>\n",
       "      <td>{'BehavioralTimeSeries': {'count': 1, 'objects...</td>\n",
       "      <td>{'BehavioralTimeSeries': {'behavior': {'name':...</td>\n",
       "      <td>[DANDI:assets/cbcf1d6d-7f64-4d1f-8692-75e09e17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>000017</td>\n",
       "      <td>DANDI:000017/0.240329.1926</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Large-scale Neuropixels recordings across brai...</td>\n",
       "      <td>{'BehavioralEpochs': {'count': 1, 'objects': [...</td>\n",
       "      <td>{'BehavioralEvents': {'mean_event_diff': 0.582...</td>\n",
       "      <td>[DANDI:assets/2c6984f5-5fd7-4ccb-8f05-1961df65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>000029</td>\n",
       "      <td>DANDI:000029/0.231017.2004</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Single unit recordings from chronically implan...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[DANDI:assets/7a3d889c-b513-40d6-b3e9-74ccb24e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>000039</td>\n",
       "      <td>DANDI:000039/0.230223.1216</td>\n",
       "      <td>[assetsSummary.approach.name, assetsSummary.va...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>{'BehavioralTimeSeries': {'count': 2, 'objects...</td>\n",
       "      <td>{'BehavioralTimeSeries': {'RunningBehavior': {...</td>\n",
       "      <td>[DANDI:assets/f2ca9a62-7034-4b58-892b-8a3cbf32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>000045</td>\n",
       "      <td>DANDI:000045/0.211209.1413</td>\n",
       "      <td>[name, citation, assetsSummary.approach.name, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ibl_neuropixel_brainwide_01</td>\n",
       "      <td>{'BehavioralTimeSeries': {'count': 1, 'objects...</td>\n",
       "      <td>{'BehavioralTimeSeries': {'BehavioralTimeSerie...</td>\n",
       "      <td>[DANDI:assets/b7855fa3-b6ee-4545-86b4-b4413095...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index dandiset_id                    dandiset  \\\n",
       "0      0      000003  DANDI:000003/0.250624.0409   \n",
       "1      2      000006  DANDI:000006/0.220126.1855   \n",
       "2      3      000009  DANDI:000009/0.220126.1903   \n",
       "3      4      000010  DANDI:000010/0.220126.1905   \n",
       "4      5      000011  DANDI:000011/0.220126.1907   \n",
       "5      6      000013  DANDI:000013/0.220126.2143   \n",
       "6      9      000017  DANDI:000017/0.240329.1926   \n",
       "7     10      000029  DANDI:000029/0.231017.2004   \n",
       "8     13      000039  DANDI:000039/0.230223.1216   \n",
       "9     15      000045  DANDI:000045/0.211209.1413   \n",
       "\n",
       "                                       behavior_keys  asset  ephys  \\\n",
       "0  [name, citation, description, assetsSummary.ap...   True   True   \n",
       "1  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "2  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "3  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "4  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "5  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "6  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "7  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "8  [assetsSummary.approach.name, assetsSummary.va...   True   True   \n",
       "9  [name, citation, assetsSummary.approach.name, ...   True   True   \n",
       "\n",
       "                              experiment_description  \\\n",
       "0                                               None   \n",
       "1  Extracellular electrophysiology recordings per...   \n",
       "2                                                      \n",
       "3  Extracellular electrophysiology recordings wit...   \n",
       "4  Extracellular electrophysiology recordings wit...   \n",
       "5  Intracellular and extracellular electrophysiol...   \n",
       "6  Large-scale Neuropixels recordings across brai...   \n",
       "7  Single unit recordings from chronically implan...   \n",
       "8                                               None   \n",
       "9                        ibl_neuropixel_brainwide_01   \n",
       "\n",
       "                                      behavior_class  \\\n",
       "0  {'SpatialSeries': {'count': 2, 'objects': [pos...   \n",
       "1  {'BehavioralEvents': {'count': 1, 'objects': [...   \n",
       "2                                                 {}   \n",
       "3  {'BehavioralEvents': {'count': 1, 'objects': [...   \n",
       "4  {'BehavioralEvents': {'count': 1, 'objects': [...   \n",
       "5  {'BehavioralTimeSeries': {'count': 1, 'objects...   \n",
       "6  {'BehavioralEpochs': {'count': 1, 'objects': [...   \n",
       "7                                                 {}   \n",
       "8  {'BehavioralTimeSeries': {'count': 2, 'objects...   \n",
       "9  {'BehavioralTimeSeries': {'count': 1, 'objects...   \n",
       "\n",
       "                                           time_info  \\\n",
       "0  {'SpatialSeries': {'position_sensor1': 'NoneTy...   \n",
       "1  {'BehavioralEvents': {'mean_event_diff': 0.981...   \n",
       "2                                                 {}   \n",
       "3  {'BehavioralEvents': {'mean_event_diff': 12.00...   \n",
       "4      {'BehavioralEvents': list index out of range}   \n",
       "5  {'BehavioralTimeSeries': {'behavior': {'name':...   \n",
       "6  {'BehavioralEvents': {'mean_event_diff': 0.582...   \n",
       "7                                                 {}   \n",
       "8  {'BehavioralTimeSeries': {'RunningBehavior': {...   \n",
       "9  {'BehavioralTimeSeries': {'BehavioralTimeSerie...   \n",
       "\n",
       "                                           filepaths  \n",
       "0  [DANDI:assets/5e9e92e1-f044-4aa0-ab47-1cfcb889...  \n",
       "1  [DANDI:assets/a5ad932b-b893-4522-b989-8f406d78...  \n",
       "2  [DANDI:assets/250ea757-e6a9-4520-99b5-f2efd5e3...  \n",
       "3  [DANDI:assets/6b3b38b9-0736-46a4-a348-b00af509...  \n",
       "4  [DANDI:assets/88dd3ee7-a37a-44b1-bb64-89855040...  \n",
       "5  [DANDI:assets/cbcf1d6d-7f64-4d1f-8692-75e09e17...  \n",
       "6  [DANDI:assets/2c6984f5-5fd7-4ccb-8f05-1961df65...  \n",
       "7  [DANDI:assets/7a3d889c-b513-40d6-b3e9-74ccb24e...  \n",
       "8  [DANDI:assets/f2ca9a62-7034-4b58-892b-8a3cbf32...  \n",
       "9  [DANDI:assets/b7855fa3-b6ee-4545-86b4-b4413095...  "
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_info = behavior_assets_dandisets.copy()\n",
    "df_time_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('Large-scale Neuropixels recordings across brain regions of mice during a head-fixed visual discrimination task. ')"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_time_info.iloc[6]\n",
    "a['experiment_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BehavioralEpochs': {'count': 1,\n",
       "  'objects': [BehavioralEpochs pynwb.behavior.BehavioralEpochs at 0x13832088592\n",
       "   Fields:\n",
       "     interval_series: {\n",
       "       wheel_moves <class 'pynwb.misc.IntervalSeries'>\n",
       "     }]},\n",
       " 'BehavioralEvents': {'count': 1,\n",
       "  'objects': [BehavioralEvents pynwb.behavior.BehavioralEvents at 0x5738999440\n",
       "   Fields:\n",
       "     time_series: {\n",
       "       lick_times <class 'pynwb.base.TimeSeries'>\n",
       "     }]},\n",
       " 'BehavioralTimeSeries': {'count': 1,\n",
       "  'objects': [BehavioralTimeSeries pynwb.behavior.BehavioralTimeSeries at 0x13832088912\n",
       "   Fields:\n",
       "     time_series: {\n",
       "       face_motion_energy <class 'pynwb.base.TimeSeries'>\n",
       "     }]},\n",
       " 'PupilTracking': {'count': 1,\n",
       "  'objects': [PupilTracking pynwb.behavior.PupilTracking at 0x13832089232\n",
       "   Fields:\n",
       "     time_series: {\n",
       "       eye_area <class 'pynwb.base.TimeSeries'>,\n",
       "       eye_xy_positions <class 'pynwb.base.TimeSeries'>\n",
       "     }]}}"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['behavior_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BehavioralEvents': {'mean_event_diff': np.float64(0.582899),\n",
       "  'std_event_diff': np.float64(1.258091)},\n",
       " 'BehavioralTimeSeries': {'BehavioralTimeSeries': TypeError(\"'NoneType' object is not subscriptable\")}}"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['time_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'face_motion_energy': face_motion_energy pynwb.base.TimeSeries at 0x5738990800\n",
      "Fields:\n",
      "  comments: The integrated motion energy across the whole frame, i.e. sum( (thisFrame-lastFrame)^2 ). Some smoothing is applied before this operation.\n",
      "  conversion: 1.0\n",
      "  data: <LindiH5pyDataset: /processing/behavior/BehavioralTimeSeries/face_motion_energy/data>\n",
      "  description: Features extracted from the video of the frontal aspect of the subject, including the subject's face and forearms.\n",
      "  offset: 0.0\n",
      "  rate: 0.02524557875164268\n",
      "  resolution: -1.0\n",
      "  starting_time: 18.115412920074125\n",
      "  starting_time_unit: seconds\n",
      "  unit: arb. unit\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(a['behavior_class']['BehavioralTimeSeries']['objects'][0].time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_motion_energy': face_motion_energy pynwb.base.TimeSeries at 0x5738990800\n",
       " Fields:\n",
       "   comments: The integrated motion energy across the whole frame, i.e. sum( (thisFrame-lastFrame)^2 ). Some smoothing is applied before this operation.\n",
       "   conversion: 1.0\n",
       "   data: <LindiH5pyDataset: /processing/behavior/BehavioralTimeSeries/face_motion_energy/data>\n",
       "   description: Features extracted from the video of the frontal aspect of the subject, including the subject's face and forearms.\n",
       "   offset: 0.0\n",
       "   rate: 0.02524557875164268\n",
       "   resolution: -1.0\n",
       "   starting_time: 18.115412920074125\n",
       "   starting_time_unit: seconds\n",
       "   unit: arb. unit}"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['behavior_class']['BehavioralTimeSeries']['objects'][0].time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "face_motion_energy pynwb.base.TimeSeries at 0x5738990800\n",
      "Fields:\n",
      "  comments: The integrated motion energy across the whole frame, i.e. sum( (thisFrame-lastFrame)^2 ). Some smoothing is applied before this operation.\n",
      "  conversion: 1.0\n",
      "  data: <LindiH5pyDataset: /processing/behavior/BehavioralTimeSeries/face_motion_energy/data>\n",
      "  description: Features extracted from the video of the frontal aspect of the subject, including the subject's face and forearms.\n",
      "  offset: 0.0\n",
      "  rate: 0.02524557875164268\n",
      "  resolution: -1.0\n",
      "  starting_time: 18.115412920074125\n",
      "  starting_time_unit: seconds\n",
      "  unit: arb. unit\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BehavioralEvents': {'mean_event_diff': np.float64(0.582899),\n",
       "  'std_event_diff': np.float64(1.258091)},\n",
       " 'BehavioralTimeSeries': {'BehavioralTimeSeries': TypeError(\"'NoneType' object is not subscriptable\")}}"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_info_from_behavior_class(a['behavior_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BehavioralEvents': {'mean_event_diff': np.float64(0.582899),\n",
       "  'std_event_diff': np.float64(1.258091)},\n",
       " 'BehavioralTimeSeries': {'BehavioralTimeSeries': TypeError(\"'NoneType' object is not subscriptable\")}}"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
